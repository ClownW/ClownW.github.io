<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta http-equiv="Cache-Control" content="no-siteapp">
  <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no">
  <meta name="renderer" content="webkit">

  
  <title>神经网络总结 | ClownW的博客</title>

  <link rel="shortcut icon" href="../images/favicon.png">
  <link rel="alternate" href="../atom.xml" title="ClownW的博客">
  <meta name="description" content="神经网络知识点总结1.为什么需要非线性的激励函数？ 如果hidden layer的激励函数是线性函数，那么可以看出这两层可以合并成新的一层，即和没有这个隐藏层直接输入没有什么区别。 对于有很多个hidden layer的深度神经网络来说，如果hidden layer的激励函数都是线性函数，那么这些隐藏层几乎都没有什么作用。 因此我们需要非线性函数来实现神经网络的功能。 2.为什么需要随机初始化？">
<meta property="og:type" content="article">
<meta property="og:title" content="神经网络总结">
<meta property="og:url" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/">
<meta property="og:site_name" content="ClownW的博客">
<meta property="og:description" content="神经网络知识点总结1.为什么需要非线性的激励函数？ 如果hidden layer的激励函数是线性函数，那么可以看出这两层可以合并成新的一层，即和没有这个隐藏层直接输入没有什么区别。 对于有很多个hidden layer的深度神经网络来说，如果hidden layer的激励函数都是线性函数，那么这些隐藏层几乎都没有什么作用。 因此我们需要非线性函数来实现神经网络的功能。 2.为什么需要随机初始化？">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E6%BF%80%E5%8A%B1%E5%87%BD%E6%95%B0.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E9%9A%8F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/overfitting.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/dropout1.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/Normalizing_input.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/sigmoid.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/tanh.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/momentum.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/RMSprop.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/adam1.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/adam2.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/adam3.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/batchnorm1.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/softmax.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/softmax_loss.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/precision_recall.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/ROC%E6%9B%B2%E7%BA%BF.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/ROC%E5%92%8CPR%E6%9B%B2%E7%BA%BF%E5%AF%B9%E6%AF%94.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E4%BF%A1%E6%81%AF%E7%86%B5.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E5%A2%9E%E7%9B%8A%E7%8E%87.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E5%9B%BA%E6%9C%89%E5%80%BC.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E5%9F%BA%E5%B0%BC%E6%8C%87%E6%95%B0.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E5%B1%9E%E6%80%A7%E7%9A%84%E5%9F%BA%E5%B0%BC%E6%8C%87%E6%95%B0.png">
<meta property="og:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/RPN.png">
<meta property="og:image" content="http://clownw.github.io/images/attention.png">
<meta property="og:image" content="http://clownw.github.io/images/%E7%8A%B6%E6%80%81%E8%BD%AC%E5%8C%96%E6%A8%A1%E5%9E%8B.png">
<meta property="og:image" content="http://clownw.github.io/images/%E7%AD%96%E7%95%A5%CF%80.png">
<meta property="og:image" content="http://clownw.github.io/images/%E4%BB%B7%E5%80%BC%E5%87%BD%E6%95%B0.png">
<meta property="og:image" content="http://clownw.github.io/images/contrast_loss.png">
<meta property="og:image" content="http://clownw.github.io/images/triplet_loss.png">
<meta property="og:image" content="http://clownw.github.io/images/triplet.png">
<meta property="og:image" content="http://clownw.github.io/images/center_loss.png">
<meta property="og:image" content="http://clownw.github.io/images/center.png">
<meta property="og:image" content="http://clownw.github.io/images/focal_loss.png">
<meta property="og:image" content="http://clownw.github.io/images/seperable_conv.png">
<meta property="og:image" content="http://clownw.github.io/images/Q-learning.png">
<meta property="og:image" content="http://clownw.github.io/images/Q-learning%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="http://clownw.github.io/images/DQN%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="http://clownw.github.io/images/transformer1.jpg">
<meta property="og:image" content="http://clownw.github.io/images/encoder-decoder%E7%BB%93%E6%9E%84.png">
<meta property="og:image" content="http://clownw.github.io/images/encoder-decoder%E7%BB%93%E6%9E%842.jpg">
<meta property="og:image" content="http://clownw.github.io/images/encoder.jpg">
<meta property="og:image" content="http://clownw.github.io/images/self-attention.png">
<meta property="og:image" content="http://clownw.github.io/images/FFN.png">
<meta property="og:image" content="http://clownw.github.io/images/decoder.jpg">
<meta property="og:image" content="http://clownw.github.io/images/%E8%BE%93%E5%85%A5.jpg">
<meta property="og:image" content="http://clownw.github.io/images/self-attention1.jpg">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=q">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=k">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=v">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Ctext%7Bscore%7D+%253D+q+%5Ccdot+k">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Csqrt%7Bd_k%7D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=v">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=v">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=z">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=z%253D%5Csum+v">
<meta property="og:image" content="http://clownw.github.io/images/self-attention2.jpg">
<meta property="og:image" content="http://clownw.github.io/images/self-attention%E7%9F%A9%E9%98%B5.jpg">
<meta property="og:image" content="http://clownw.github.io/images/self-attention%E7%9F%A9%E9%98%B51.jpg">
<meta property="og:image" content="http://clownw.github.io/images/encoder%E6%AE%8B%E5%B7%AE.jpg">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=h">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=h%253D8">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=X+">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=Z_i%252C+i%5Cin%5C%7B1%252C2%252C...%252C8%5C%7D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=Z_i">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=Z">
<meta property="og:image" content="http://clownw.github.io/images/multi-head.jpg">
<meta property="og:image" content="http://clownw.github.io/images/transformer%E5%AE%8C%E6%95%B4%E7%BB%93%E6%9E%84.jpg">
<meta property="og:image" content="http://clownw.github.io/images/%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81.jpg">
<meta property="article:published_time" content="2020-03-26T14:48:55.000Z">
<meta property="article:modified_time" content="2020-06-01T13:32:43.449Z">
<meta property="article:author" content="ClownW">
<meta property="article:tag" content="神经网络">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E6%BF%80%E5%8A%B1%E5%87%BD%E6%95%B0.png">

  <meta name="format-detection" content="telephone=no,email=no">
  <meta name="theme-color" content="#9C27B0">
  <meta name="description" content="">
  <meta name="keywords" content=",神经网络">

  <meta name="mobile-web-app-capable" content="yes">
  <meta name="application-name" content="ClownW的博客">
  <meta name="msapplication-starturl" content="http://clownw.github.io">
  <meta name="msapplication-navbutton-color" content="#9C27B0">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-title" content="ClownW的博客">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon" href="../images/favicon.png">

  
    <meta property="article:published_time" content="Thu Mar 26 2020 22:48:55 GMT+0800">
    <meta property="article:modified_time" content="Mon Jun 01 2020 21:32:43 GMT+0800">
  

  
    <link rel="canonical" href="http://clownw.github.io">
  

  
  

  
  
  

  
<link rel="stylesheet" href="../css/mdui.css">
<link rel="stylesheet" href="../css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>
<body class="mdui-appbar-with-toolbar mdui-drawer-body-left mdui-theme-primary-indigo mdui-theme-accent-pink">
  <script>var a=localStorage.getItem("mdui-theme-layout-dark");if(a){document.getElementsByTagName("body")[0].className+=" mdui-theme-layout-dark"};</script>
  <header id="header" class="mdui-appbar mdui-appbar-fixed mdui-appbar-scroll-hide mdui-appbar-inset">
  <div class="mdui-toolbar mdui-color-theme">
    <a href="javascript:;" class="mdui-btn mdui-btn-icon" mdui-drawer="{target: '#sidebar', swipe: true}"><i class="mdui-icon material-icons">menu</i></a>
    <a href="../index.html" class="mdui-typo-headline">ClownW的博客</a>
    <div class="mdui-toolbar-spacer"></div>
    <a href="javascript:;" class="mdui-btn mdui-btn-icon" mdui-dialog="{target: '#search'}" mdui-tooltip="{content: '搜索'}"><i class="mdui-icon material-icons">search</i></a>
    <a href="../atom.xml" class="mdui-btn mdui-btn-icon" mdui-tooltip="{content: 'RSS'}"><i class="mdui-icon material-icons">rss_feed</i></a>
  </div>
</header>
<div class="mdui-dialog" id="search">
  
    <div class="search-form">
      <input type="search" class="search-form-input" placeholder="Enter the key words">
    </div>
    <div class="search-result" data-resource="../search.xml"></div>
  
</div>
  <aside id="sidebar" class="mdui-drawer mdui-drawer-full-height">
  <div class="mdui-grid-tile">
    <img src="../images/banner.png" style="height: 160px;">
    <img src="../images/portrait.png" class="avatar-animation" style="position: absolute; top: 10%; left: 24px; width: 64px; height: 64px; border: 2px solid #fff; border-radius: 50%;">
    <div class="mdui-grid-tile-actions">
      <div class="mdui-grid-tile-text">
        <div class="mdui-grid-tile-title">ClownW</div>
        <div class="mdui-grid-tile-subtitle"><i class="mdui-icon material-icons">art_track</i></div>
      </div>
      
    </div>
  </div>

  <div class="mdui-list" mdui-collapse="{accordion: true}">
    <a href="../index.html" class="mdui-list-item mdui-ripple">
      <i class="mdui-list-item-icon mdui-icon material-icons mdui-text-color-blue">home</i>
      <div class="mdui-list-item-content">主页</div>
    </a>
    <div class="mdui-collapse-item">
      <div class="mdui-collapse-item-header mdui-list-item mdui-ripple">
        <i class="mdui-list-item-icon mdui-icon material-icons mdui-text-color-deep-orange">inbox</i>
        <div class="mdui-list-item-content">归档</div>
        <i class="mdui-collapse-item-arrow mdui-icon material-icons">keyboard_arrow_down</i>
      </div>
      <div class="mdui-collapse-item-body mdui-list mdui-list-dense">
        
        <a class="mdui-ripple sidebar_archives-link" href="../archives/2020/05/">五月 2020<span class="mdui-ripple sidebar_archives-count">3</span></a><a class="mdui-ripple sidebar_archives-link" href="../archives/2020/04/">四月 2020<span class="mdui-ripple sidebar_archives-count">1</span></a><a class="mdui-ripple sidebar_archives-link" href="../archives/2020/03/">三月 2020<span class="mdui-ripple sidebar_archives-count">5</span></a><a class="mdui-ripple sidebar_archives-link" href="../archives/2020/02/">二月 2020<span class="mdui-ripple sidebar_archives-count">8</span></a><a class="mdui-ripple sidebar_archives-link" href="../archives/2020/01/">一月 2020<span class="mdui-ripple sidebar_archives-count">1</span></a>
        
      </div>
    </div>
    <div class="mdui-collapse-item">
      <div class="mdui-collapse-item-header mdui-list-item mdui-ripple">
        <i class="mdui-list-item-icon mdui-icon material-icons mdui-text-color-green">chrome_reader_mode</i>
        <div class="mdui-list-item-content">分类</div>
        <i class="mdui-collapse-item-arrow mdui-icon material-icons">keyboard_arrow_down</i>
      </div>
      <div class="mdui-collapse-item-body mdui-list mdui-list-dense">
        
        
        
          <a href="javascript:;" class="mdui-list-item mdui-ripple mdui-p-l-2 mdui-text-color-theme" style="justify-content: center;">分类为空</a>
        
      </div>
    </div>
    <div class="mdui-collapse-item">
      <div class="mdui-collapse-item-header mdui-list-item mdui-ripple">
        <i class="mdui-list-item-icon mdui-icon material-icons mdui-text-color-brown">bookmark</i>
        <div class="mdui-list-item-content">标签</div>
        <i class="mdui-collapse-item-arrow mdui-icon material-icons">keyboard_arrow_down</i>
      </div>
      <div class="mdui-collapse-item-body mdui-list mdui-list-dense">
        
        <a class="mdui-ripple sidebar_archives-link" href="../tags/Leetcode-Top-Interview-Questions/" rel="tag">Leetcode Top Interview Questions<span class="mdui-ripple sidebar_archives-count">7</span></a><a class="mdui-ripple sidebar_archives-link" href="../tags/learn/" rel="tag">learn<span class="mdui-ripple sidebar_archives-count">1</span></a><a class="mdui-ripple sidebar_archives-link" href="../tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">神经网络<span class="mdui-ripple sidebar_archives-count">1</span></a><a class="mdui-ripple sidebar_archives-link" href="../tags/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/" rel="tag">算法学习<span class="mdui-ripple sidebar_archives-count">1</span></a><a class="mdui-ripple sidebar_archives-link" href="../tags/%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/" rel="tag">算法总结<span class="mdui-ripple sidebar_archives-count">7</span></a>
        
      </div>
    </div>
    <a href="../about" class="mdui-list-item mdui-ripple">
      <i class="mdui-list-item-icon mdui-icon material-icons mdui-text-color-purple">person</i>
      <div class="mdui-list-item-content">关于</div>
    </a>
  </div>

  <div class="mdui-divider"></div>

  <div class="mdui-list" mdui-collapse="{accordion: true}">
    
    <div class="mdui-collapse-item">
      <div class="mdui-collapse-item-header mdui-list-item mdui-ripple">
        <div class="mdui-list-item-content">友情链接</div>
        <i class="mdui-list-item-icon mdui-icon material-icons">link</i>
      </div>
      <div class="mdui-collapse-item-body mdui-list mdui-list-dense">
        
          <a href="https://github.com/ClownW" target="_blank" class="mdui-list-item mdui-ripple mdui-p-l-2 mdui-text-color-theme-accent" style="justify-content: center;">My github profile</a>
        
        
      </div>
    </div>
  </div>
</aside>
  <main id="main" class="mdui-m-t-5 fadeIn animated">
  
<link rel="stylesheet" href="../https:/cdn.bootcss.com/fancybox/3.5.7/jquery.fancybox.min.css">

  <style>#main article .mdui-card-content .center-block{display:block!important;margin-right:auto!important;margin-left:auto!important}</style>
  <article class="mdui-card mdui-m-b-5">
    <header class="mdui-card-media">
      <img src="/images/random/material-17.png" style="max-height: 240px;">
      <div class="mdui-card-media-covered">
        <div class="mdui-card-primary">
          <div class="mdui-card-primary-title">神经网络总结</div>
          <div class="mdui-card-primary-subtitle"><i class="iconfont">&#xe697;</i> 2020-03-26 / <i class="iconfont">&#xe601;</i> ClownW</div>
        </div>
      </div>
      <div class="mdui-card-menu">
        
          <button class="mdui-btn mdui-btn-icon mdui-text-color-white" mdui-menu="{target: '#qrcode', align: 'right'}"><i class="mdui-icon material-icons">devices</i></button>
          <ul class="mdui-menu" id="qrcode">
            
              <li class="mdui-menu-item"><a class="mdui-text-center mdui-ripple">Send to mobile phone</a></li>
            
            <li class="mdui-menu-item" disabled>
              
                <img src="http://qr.liantu.com/api.php?w=246&m=10&text=http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/">
              
            </li>
          </ul>
        
        
          <button class="mdui-btn mdui-btn-icon mdui-text-color-white" mdui-menu="{target: '#share_menu', align: 'right'}"><i class="mdui-icon material-icons">share</i></button>
          <ul class="mdui-menu" id="share_menu">
            <li class="mdui-menu-item">
              <a href="http://service.weibo.com/share/share.php?appkey=&title=神经网络总结&url=http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/&pic=http://clownw.github.io../images/favicon.png&searchPic=false&style=simple" target="_blank" class="mdui-ripple">分享到微博</a>
            </li>
            <li class="mdui-menu-item">
              <a href="https://twitter.com/intent/tweet?text=神经网络总结&url=http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/&via=ClownW" target="_blank" class="mdui-ripple">分享到Twitter</a>
            </li>
            <li class="mdui-menu-item">
              <a href="https://www.facebook.com/sharer/sharer.php?u=http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/" target="_blank" class="mdui-ripple">分享到Facebook</a>
            </li>
            <li class="mdui-menu-item">
              <a href="https://plus.google.com/share?url=http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/" target="_blank" class="mdui-ripple">分享到Google+</a>
            </li>
            <li class="mdui-menu-item">
              <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/&title=神经网络总结" target="_blank" class="mdui-ripple">分享到LinkedIn</a>
            </li>
            <li class="mdui-menu-item">
              <a href="http://connect.qq.com/widget/shareqq/index.html?site=ClownW的博客&title=神经网络总结&summary=&pics=http://clownw.github.io../images/favicon.png&url=http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/" target="_blank" class="mdui-ripple">分享到QQ</a>
            </li>
            <li class="mdui-menu-item">
              <a href="https://telegram.me/share/url?url=http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/&text=神经网络总结" target="_blank" class="mdui-ripple">分享到Telegram</a>
            </li>
          </ul>
        
      </div>
    </header>
    <div class="mdui-card-content mdui-typo">
      <h1 id="神经网络知识点总结"><a href="#神经网络知识点总结" class="headerlink" title="神经网络知识点总结"></a>神经网络知识点总结</h1><h3 id="1-为什么需要非线性的激励函数？"><a href="#1-为什么需要非线性的激励函数？" class="headerlink" title="1.为什么需要非线性的激励函数？"></a>1.为什么需要非线性的激励函数？</h3><p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E6%BF%80%E5%8A%B1%E5%87%BD%E6%95%B0.png" alt=""></p>
<p>如果hidden layer的激励函数是线性函数，那么可以看出这两层可以合并成新的一层，即和没有这个隐藏层直接输入没有什么区别。</p>
<p>对于有很多个hidden layer的深度神经网络来说，如果hidden layer的激励函数都是线性函数，那么这些隐藏层几乎都没有什么作用。</p>
<p>因此我们需要非线性函数来实现神经网络的功能。</p>
<h3 id="2-为什么需要随机初始化？"><a href="#2-为什么需要随机初始化？" class="headerlink" title="2.为什么需要随机初始化？"></a>2.为什么需要随机初始化？</h3><p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E9%9A%8F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96.png" alt=""></p>
<p>​        如果将W全部初始化为0，在logistic regression中是可行的，但是在神经网络中这样会使得所有的隐藏层计算的函数都相同，无论经过多少次梯度下降这些隐藏层神经元计算的函数都是相同的，而我们需要不同的隐藏层单元来计算不同的函数，因此需要进行随机初始化。</p>
<p>​        随机初始化的方法：W[1] = np.random.randn((2, 2)) * 0.01</p>
<p>​        为什么要乘一个0.01？因为sigmoid和tanh函数在z很大或者很小的时候梯度都趋近于0，所以说应尽量使z的值比较小，这样进行梯度下降才能更快得学习。</p>
<h3 id="3-手写前向传播？"><a href="#3-手写前向传播？" class="headerlink" title="3.手写前向传播？"></a>3.手写前向传播？</h3><p>先略过。</p>
<h3 id="4-偏差（bias）和方差-variance"><a href="#4-偏差（bias）和方差-variance" class="headerlink" title="4.偏差（bias）和方差(variance)"></a>4.偏差（bias）和方差(variance)</h3><p>高偏差解决方法：</p>
<p>1.更大的网络</p>
<p>2.Train larger</p>
<p>3.网络结构搜索</p>
<p>高方差解决方法：</p>
<p>1.更多的数据</p>
<p>2.正则化</p>
<p>3.网络结构搜索</p>
<h3 id="5-正则化能减少overfitting的原因"><a href="#5-正则化能减少overfitting的原因" class="headerlink" title="5.正则化能减少overfitting的原因"></a>5.正则化能减少overfitting的原因</h3><p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/overfitting.png" alt=""></p>
<p>解释一：</p>
<p>当一个神经网络出现high variance问题时，如果设置lambda为一个很大的值，则W会趋近于0，这样这个深度神经网络很多个神经元的 权值就几乎为0，也会导致这个神经网络变得很简单，简单的神经网络无法做出复杂的分类，因此会由high variance变为high bias。<strong>在这中间必然有某个lambda会使得整个神经网络工作just right。</strong></p>
<p>解释二：</p>
<p>当lambda很大时，W很小，导致Z也很小，因此在激励函数tanh的线性区域内，整个神经网络几乎都在做线性计算，因此无法计算出复杂的decision boundry，自然也就无法拟合到过拟合那样复杂的decision boundary。</p>
<h3 id="6-Dropout-理解"><a href="#6-Dropout-理解" class="headerlink" title="6.Dropout 理解"></a>6.Dropout 理解</h3><p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/dropout1.png" alt=""></p>
<p>使用drop out方法来减少正则化，以相同的概率随机drop out掉每一个隐藏层的神经元。</p>
<p>这样相当于每次只使用一个小神经网络来进行训练。</p>
<p><strong>有关keep_prob和scaling</strong></p>
<p>​        设置keep_prob,这是保留每层的神经元的概率，keep_prob = 0.8表示要每个神经元有0.8的概率被保留。</p>
<p>​        对于l = 3的第三层来说，设置一个概率矩阵 d3 = np.random.rand(a3.shape[0], a3.shape[1]) &lt; keep_prob。得到一个全部为True和Fales的矩阵，用这个矩阵和a3进行对应元相乘，a3 = np.multiply(a3, d3)</p>
<p>​        最后还需要scaling a3，令a3 = a3/keep_prob</p>
<p>​        最后一步的原因是我们只希望drop掉某些神经元，但并不希望改变a3的值，如果不进行scaling则最后a3的值会变小约20%，因此需要进行scaling。这种最后进行scaling的方法又叫inverted dropout</p>
<p><strong>有关scaling：</strong></p>
<p>简单讲就是：</p>
<p>训练有scale，测试不用管。</p>
<p>训练没scale，测试要乘p。</p>
<p><strong>dropout起作用的原因：</strong></p>
<p>​        dropout起作用的原因：<strong>试想对input进行dropout,则会有一些features被dropout掉，这使得输出无法过多得依赖某个特征，因此避免了overfitting</strong></p>
<p>​        对于一个深度神经网络，我们可以对每一层设置不同的keep_prob,对于我们认为可能会导致dropout的层设置更小的keep_prob，对于认为不太会发生overfitting的层几乎不进行dropout，设置keep_prob为1</p>
<p><strong>dropout的缺点：</strong></p>
<p>使用dropout的一个<strong>缺点是我们的cost function J的抖动变大。</strong></p>
<h3 id="7-其他正则化"><a href="#7-其他正则化" class="headerlink" title="7.其他正则化"></a>7.其他正则化</h3><p>1.Data augmentation</p>
<p>2.early stopping</p>
<p>另一种方法是进行early stopping，在发现dev set error开始上升的时候停止训练，取这个时候的模型参数来阻止overfittiing。<strong>缺点是可能使cost function J没有优化到最优。</strong></p>
<p>而当用L2 regularization的时候，<strong>缺点是要选择超参数lambda的值，需要很大的计算量。当计算能力足够的时候，L2 regularization会优于 early stopping。</strong></p>
<h3 id="8-输入标准化（Normalizing-inputs）"><a href="#8-输入标准化（Normalizing-inputs）" class="headerlink" title="8.输入标准化（Normalizing inputs）"></a>8.输入标准化（Normalizing inputs）</h3><p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/Normalizing_input.png" alt=""></p>
<p>通过左右对比可以发现，normalizing以后的输入，更有利于找到最优解，因此通过normalization可以使梯度下降更快得找到全局最优点。</p>
<h3 id="9-梯度消失和梯度爆炸"><a href="#9-梯度消失和梯度爆炸" class="headerlink" title="9.梯度消失和梯度爆炸"></a>9.梯度消失和梯度爆炸</h3><p><strong>梯度消失原因：</strong></p>
<p>1.网络过深</p>
<p>2.采用了不合适的损失函数</p>
<p><strong>梯度爆炸原因：</strong></p>
<p>1.网络过深</p>
<p>2.权值初始化太大</p>
<p><strong>从深层网络角度讲：</strong>从深层网络角度来讲，不同的层学习的速度差异很大，表现为网络中靠近输出的层学习的情况很好，靠近输入的层学习的很慢，有时甚至训练了很久，前几层的权值和刚开始随机初始化的值差不多。因此，梯度消失、爆炸，其根本原因在于反向传播训练法则，属于先天不足，可以考虑hinton提出的capsule网络。<br><strong>从激活函数角度：</strong></p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/sigmoid.png" alt=""></p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/tanh.png" alt=""></p>
<p>sigmoid和tanh函数的导数最大值都小于1，因此经过链式求导后，很容易发生梯度消失。</p>
<p><strong>梯度爆炸解决方法：</strong></p>
<p>梯度剪切，正则化（如果发生梯度爆炸，权值的范数就会变得非常大，而正则化项可以约束这一点）</p>
<p><strong>而在深度神经网络中，往往梯度消失发生得更多一些</strong></p>
<p><strong>梯度消失解决方法：</strong></p>
<p>1.修改激活函数</p>
<p>2.batchnorm，反向传播式子中有x的存在，而batchnorm规范了每一层的均值和方差，消除了x带来的放大缩小的影响，从而有助于解决梯度消失或梯度爆炸。</p>
<p>3.使用残差结构</p>
<h3 id="10-Momentum，RMSprop，Adam方法"><a href="#10-Momentum，RMSprop，Adam方法" class="headerlink" title="10.Momentum，RMSprop，Adam方法"></a>10.Momentum，RMSprop，Adam方法</h3><h4 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h4><p>当我们采用小的学习率的时候，会导致网络在训练的时候收敛太慢；当我们采用大的学习率的时候，会导致在训练过程中优化的幅度跳过函数的范围，也就是可能跳过最优点。我们所希望的仅仅是网络在优化的时候网络的损失函数有一个很好的收敛速度同时又不至于摆动幅度太大。</p>
<p>Momentum优化器可以解决这个问题，平均了此前积累的速度，降低了摆动幅度。</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/momentum.png" alt=""></p>
<p>对于每次迭代中（对于mini-batch中的某个t）：</p>
<p>计算Vdw = βVdw + (1-β)dw</p>
<p>​    Vdb = βVdb + (1-β)db</p>
<p>在更新W和b时：利用公式Vθ = βVθt + （1 - β）θt</p>
<p>W = W - αVdw</p>
<p>b = b - αVdb</p>
<p>用Vdw和Vdb来更新W和b</p>
<p>相比于用dw和db来更新的好处：</p>
<p>取了前面若干dw和db的平均值来进行计算，比如在纵向，平均值为0，成功减小了纵向的学习速率，对于横向依然保持一个较快的学习速率。这样就使得学习更为平滑，从而加快了收敛。</p>
<p>对于公式的理解:</p>
<p>Vdw = βVdw + (1-β)dw</p>
<p>Vdb = βVdb + (1-β)db</p>
<p>其中dw,db可以认为是加速项，Vdw,Vdb看做速度，β小于1，可以用来防止速度无限增大</p>
<h4 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h4><p>进一步优化了损失函数在更新中摆幅过大的问题，并进一步加快函数的收敛速度。</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/RMSprop.png" alt=""></p>
<p>算法利用$S_{dw}$来表示前t-1轮迭代过程的梯度动量，当摆幅大的时候，$S_{dw}$就大，放在分母中，就更大程度得减少了W的更新，从而降低了摆幅。为了防止分母为0，加上了一个平滑数。</p>
<h4 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h4><p>结合前面二者的优点。</p>
<p>假设在训练的第 tt 轮训练中，我们首先可以计算得到Momentum和RMSProp的参数更新：</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/adam1.png" alt=""></p>
<p>由于移动指数平均在迭代开始的初期会导致和开始的值有较大的差异，所以我们需要对上面求得的几个值做偏差修正。</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/adam2.png" alt=""></p>
<p>更新公式：</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/adam3.png" alt=""></p>
<h3 id="11-批标准化"><a href="#11-批标准化" class="headerlink" title="11.批标准化"></a>11.批标准化</h3><p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/batchnorm1.png" alt=""></p>
<p>推荐对z（即神经网络的直接输出，此时还没有经过激励函数）进行标准化。</p>
<p><strong>批标准化实现：</strong>如图所示，先将z标准化为均值为0，方差为1的z_norm，再引入参数β，γ来调整z的均值和方差。β，γ利用梯度下降来进行更新。</p>
<p>在深度学习框架中，这些都被封装起来。</p>
<p><strong>批标准化的作用：</strong></p>
<p>1.提升了训练速度，使收敛速度大大加快</p>
<p>2.简化调参过程，对于参数初始化的要求降低，可以使用大的学习率</p>
<p><strong>提升训练速度的原因：</strong></p>
<p>a) 稳定学习效果。机器学习领域有个很重要的假设：<strong>IID独立同分布假设</strong>，就是假设训练数据和测试数据是满足相同分布的，这是通过训练数据获得的模型能够在测试集获得好的效果的一个基本保障。<strong>BatchNorm就是在深度神经网络训练过程中使得每一层神经网络的输入保持相同分布的。</strong>如果任由输入的分布变化而不加约束，网络就很难稳定得学习规律。</p>
<p>b) 加速收敛。因为深层神经网络在做非线性变换前的<strong>激活输入值</strong>（就是那个x=WU+B，U是输入）<strong>随着网络深度加深或者在训练过程中，其分布逐渐发生偏移或者变动，之所以训练收敛慢，一般是整体分布逐渐往非线性函数的取值区间的上下限两端靠近</strong>（对于Sigmoid函数来说，意味着激活输入值WU+B是大的负值或正值），所以这<strong>导致反向传播时低层神经网络的梯度消失</strong>，这是训练深层神经网络收敛越来越慢的<strong>本质原因</strong>，<strong>而BN就是通过一定的规范化手段，把每层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布</strong>，</p>
<h3 id="12-Softmax"><a href="#12-Softmax" class="headerlink" title="12.Softmax"></a>12.Softmax</h3><p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/softmax.png" alt=""></p>
<p>softmax的计算如图，当C=2，即只有两个类时，就退化为logistic函数。</p>
<p>loss函数的计算：</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/softmax_loss.png" alt=""></p>
<h3 id="13-precision和recall，PR-曲线，ROC曲线与AUC值"><a href="#13-precision和recall，PR-曲线，ROC曲线与AUC值" class="headerlink" title="13. precision和recall，PR-曲线，ROC曲线与AUC值"></a>13. precision和recall，PR-曲线，ROC曲线与AUC值</h3><p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/precision_recall.png" alt=""></p>
<p>$precision = \frac{TP}{TP+FP}$    $recall = \frac{TP}{TP+FN}$ </p>
<p>从公式可以看出:</p>
<p>precision表示被检测为真的，有多少实际为真</p>
<p>recall表示实际为真的，有多少被检测到为真了</p>
<p>$F_1 = \frac{1}{\frac{1}{P}+\frac{1}{R}}$</p>
<p>但从precision和recall来看检测效果都是片面的，因此引入F1-score来综合考量这两个指标。</p>
<p>选取不同的阈值可以得到多组precision与recall，每组在P-R曲线上就是一个点，将这些点连接起来，就得到了P-R曲线。</p>
<p><strong>ROC曲线：</strong>和P-R曲线的定义类似，首先引入两个变量。（TPR和recall的计算相同）</p>
<p>  $TPR = \frac{TP}{TP+FN}$，$FPR = \frac{FP}{FP+TN}$</p>
<p>选取多个阈值，可以得到多组TPR和FPR的值。比如阈值0.6，则预测概率大于0.6的被分类为正类，小于0.6的被分类为负类，这样就可以计算所有样本的TP,FP,TN,FN。</p>
<p>得到了多组TPR，FPR后就可以做出ROC曲线，即ROC曲线上的每一个点都代表着一个不同的阈值。</p>
<p><strong>极端分析：</strong></p>
<p>TPR表示被正确预测出来的正例占所有正例的比例，FPR表示被错误预测为正例的样本占所有负例的比例，我们希望TPR越大越好，FPR越小越好。</p>
<p>当阈值为1时，没有样本被预测为正例，因此得到ROC曲线上的（0, 0）。</p>
<p>当阈值为0时，所有样本被预测为正例，因此得到ROC曲线上的（1, 1）。</p>
<p>理想情况下，TPR要接近1，FPR要接近0。</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/ROC%E6%9B%B2%E7%BA%BF.png" alt=""></p>
<center><font size=2>随着阈值调整，ROC坐标系中点的变化</font></center>
可以看出，ROC曲线一般会分布在y=x直线上方。

<p><strong>AUC值：</strong>AUC被定义为ROC曲线下的面积，一般ROC曲线都会分布在y=x这条曲线的上方，所以AUC的取值范围一般在0.5和1之间。可以使用AUC来判断这个分类器的性能。</p>
<ul>
<li><p>AUC = 1，是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器。</p>
</li>
<li><p>0.5 &lt; AUC &lt; 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。</p>
</li>
<li><p>AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。</p>
</li>
<li><p>AUC &lt; 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。</p>
</li>
</ul>
<p>简单来说，AUC值越大的分类器，分类效果越好。</p>
<p><strong>问：为什么AUC值不受样本分布的影响？</strong></p>
<p>观察TPR和FPR的定义可以知道，TPR的计算考虑的都是样本的实际正例，FPR的计算考虑的都是样本的实际负例，因此正负样本比例不均衡不影响ROC曲线，比如负样本增加到原来的10倍或者被随机丢弃一半，可以简单认为AUC值不变。<strong>但P-R曲线受到样本分布的影响较大。</strong></p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/ROC%E5%92%8CPR%E6%9B%B2%E7%BA%BF%E5%AF%B9%E6%AF%94.png" alt=""></p>
<p>a,c为ROC曲线，b,d为PR曲线。(a)和(b)展示的是分类其在原始测试集(正负样本分布平衡)的结果，(c)(d)是将测试集中负样本的数量增加到原来的10倍后，分类器的结果，可以明显的看出，ROC曲线基本保持原貌，而PR曲线变化较大。</p>
<h3 id="14-mAP"><a href="#14-mAP" class="headerlink" title="14.mAP"></a>14.mAP</h3><p>mAP中的m表示mean，表示不同类别AP的平均值。首先对每个类别计算AP。</p>
<p>首先确定，mAP是衡量目标检测效果的一个指标。AP的计算要先计算precision和recall。</p>
<p>对于一个预测框来说，有两个阈值影响它的标记。一个是IOU_threshold，另一个是p_threshold。低于IOU_threshold的框我们认为是False Positive，高于IOU_threshold的框认为是True Positive。</p>
<p>而对于p_threshold，表示有多大的概率是某个类别，阈值以上的都是positive，阈值一下的都是negative。</p>
<p>根据预测结果与ground truth，可以计算每个positive框与ground truth的IoU，取最大的那个认为检测到了物体，在根据IoU阈值可以计算出true positive和false positive。可以得到各个类别的precision。</p>
<p>得到了true positive后，false negative表示漏检的目标，这个也是好计算的，也就可以得到recall。</p>
<p><strong>现在已经得到了在一个确定的IoU_threshold和一个确定的p_threshold下的precision和recall。</strong></p>
<p>为了得到P-R曲线，首先对预测结果按照置信度排序，给定一个rank，每个rank对应了一个p_threshold，就可以计算出不同p_threshold下的precision和recall，取这些recall下<strong>precision</strong>的平均值就作为AP。</p>
<p>将不同类别目标的AP取平均就得到了mAP。</p>
<h3 id="14-决策树"><a href="#14-决策树" class="headerlink" title="14.决策树"></a>14.决策树</h3><h4 id="ID3和C4-5决策树算法。"><a href="#ID3和C4-5决策树算法。" class="headerlink" title="ID3和C4.5决策树算法。"></a>ID3和C4.5决策树算法。</h4><p>不同的算法有不同的依据来划分节点。ID3根据信息增益来划分节点，而C4.5根据信息增益率来划分节点。</p>
<p>信息熵定义：</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E4%BF%A1%E6%81%AF%E7%86%B5.png" alt=""></p>
<p>信息增益定义：</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A.png" alt=""></p>
<p>其中,D为所有样本的集合，pk为样本集合D中第k类样本所占的比例，γ为样本类别数。</p>
<p>一般而言，信息增益越大，则意味着用属性a来进行划分所获得的“纯度提升”越大。</p>
<p><strong>实际上，信息增益准则对可取值数目较多的属性有所偏好，因此C4.5不直接使用信息增益，而是从信息增益高于平均水平的属性中，选择增益率最高的一个。</strong></p>
<p>增益率定义：</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E5%A2%9E%E7%9B%8A%E7%8E%87.png" alt=""></p>
<p>其中，</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E5%9B%BA%E6%9C%89%E5%80%BC.png" alt=""></p>
<p><strong>增益率对可取值数目较少的属性有所偏好</strong></p>
<h4 id="基尼指数"><a href="#基尼指数" class="headerlink" title="基尼指数"></a>基尼指数</h4><p>CART决策树使用基尼指数来选择划分属性。</p>
<p>CART是 Classification and Regression Tree的简称，分类和回归任务都可用。</p>
<p>基尼指数定义：</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E5%9F%BA%E5%B0%BC%E6%8C%87%E6%95%B0.png" alt=""></p>
<p>基尼指数反应了从数据集D中随机抽取两个样本，其类别标记不一致的概率，因此Gini(D)越小，则数据集D的纯度越高。</p>
<p>属性a的基尼指数定义为：</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/%E5%B1%9E%E6%80%A7%E7%9A%84%E5%9F%BA%E5%B0%BC%E6%8C%87%E6%95%B0.png" alt=""></p>
<p>CART决策树在候选属性集合A中，选择那个使得划分后基尼指数最小的属性作为最优划分属性。</p>
<h3 id="15-R-CNN-Fast-R-CNN-Faster-R-CNN"><a href="#15-R-CNN-Fast-R-CNN-Faster-R-CNN" class="headerlink" title="15. R-CNN, Fast R-CNN, Faster R-CNN"></a>15. R-CNN, Fast R-CNN, Faster R-CNN</h3><p><strong>RCNN:</strong></p>
<p>主要步骤：</p>
<ol>
<li>输入测试图像</li>
<li>利用选择性搜索Selective Search算法在图像中从下到上提取2000个左右的可能包含物体的候选区域Region Proposal</li>
<li>因为取出的区域大小各自不同，所以需要将每个Region Proposal缩放（warp）成统一的227x227的大小并输入到CNN，将CNN的fc7层的输出作为特征</li>
<li>将每个Region Proposal提取到的CNN特征输入到SVM进行分类</li>
</ol>
<p>缺点：要提取2000个region并且都要输入到CNN中进行特征提取，进行了大量的重复运算</p>
<p><strong>Fast R-CNN:</strong></p>
<p>与RCNN的对比</p>
<p>原来的方法：许多候选框（比如两千个）–&gt;CNN–&gt;得到每个候选框的特征–&gt;分类+回归<br>现在的方法：一张完整图片–&gt;CNN–&gt;得到每张候选框的特征–&gt;分类+回归</p>
<p>也就是说Fast R-CNN是对整张图做一次卷积，然后把候选框映射到feature map上，而不是对每个候选框都输入CNN做特征提取，减少了重复计算。并且直接使用神经网络来进行分类和回归，不再使用SVM。</p>
<p><strong>Faster R-CNN:</strong></p>
<p>Fast R-CNN存在的问题：存在瓶颈：选择性搜索，找出所有的候选框，这个也非常耗时。</p>
<p>解决方法：加入一个提取边缘的神经网络，也就说找到候选框的工作也交给神经网络来做了。</p>
<p>在Fast R-CNN中引入Region Proposal Network(RPN)替代Selective Search，同时引入anchor box应对目标形状的变化问题</p>
<p>具体做法：<br>　　• 将RPN放在最后一个卷积层的后面<br>　　• RPN直接训练得到候选区域</p>
<p>![](神经网络总结/faster R-CNN.png)</p>
<p>RPN简介：<br>　　• 在feature map上滑动窗口<br>　　• 建一个神经网络用于物体分类+框位置的回归<br>　　• 滑动窗口的位置提供了物体的大体位置信息<br>　　• 框的回归提供了框更精确的位置</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/RPN.png" alt=""></p>
<p>R-CNN系列和yolo的区别：由于采用了region proposal，faster RCNN鲁棒性好精确性方面会好一些，也由于region proposal的耗时操作，导致其速度会比yolo，ssd更慢。</p>
<h3 id="16-attention机制"><a href="#16-attention机制" class="headerlink" title="16.attention机制"></a>16.attention机制</h3><p>​        attention作用：“去伪存真”，让任务处理系统<strong>更专注于找到输入数据中显著的与当前输出相关的有用信息</strong>，从而提高输出的质量。Attention模型的最终目的是帮助类似编解码器这样的框架，更好的学到多种内容模态之间的相互关系，从而更好的表示这些信息，克服其无法解释从而很难设计的缺陷。</p>
<p>​        深度学习中的注意力机制从本质上讲和人类的选择性视觉注意力机制类似，核心目标也是从众多信息中选择出对当前任务目标更关键的信息。</p>
<p><img src="../images/attention.png" alt=""></p>
<p>​        如图是encoder-decoder机制，要计算Hi时，利用Hi-1与encoder的各个部分输出来计算相似度（可以利用神经网络来算），最后经过softmax归一化后得到attention，这里的相似度计算就是衡量应该更加注重哪个部分。</p>
<h3 id="17-强化学习中的马尔卡夫决策过程"><a href="#17-强化学习中的马尔卡夫决策过程" class="headerlink" title="17.强化学习中的马尔卡夫决策过程"></a>17.强化学习中的马尔卡夫决策过程</h3><p>马尔科夫假设：假设下一个状态相关的决策仅与上一个状态有关，而与之前的无关。</p>
<p>环境的状态转化模型：在状态s下采取动作a转移到下一个状态s‘的概率，用$P_{ss’}^{a}$来表示，利用马尔科夫假设，</p>
<p><img src="../images/%E7%8A%B6%E6%80%81%E8%BD%AC%E5%8C%96%E6%A8%A1%E5%9E%8B.png" alt=""></p>
<p>策略π：</p>
<p><img src="../images/%E7%AD%96%E7%95%A5%CF%80.png" alt=""></p>
<p>价值函数$v_π(s)$，也依据马尔科夫假设：</p>
<p><img src="../images/%E4%BB%B7%E5%80%BC%E5%87%BD%E6%95%B0.png" alt=""></p>
<p>其中，Gt代表收获（return), 是一个MDP中从某一个状态StSt开始采样直到终止状态时所有奖励的有衰减的之和。</p>
<h3 id="18-强化学习中的reward如何设计？"><a href="#18-强化学习中的reward如何设计？" class="headerlink" title="18.强化学习中的reward如何设计？"></a>18.强化学习中的reward如何设计？</h3><h3 id="19-强化学习中的policy如何设计？"><a href="#19-强化学习中的policy如何设计？" class="headerlink" title="19.强化学习中的policy如何设计？"></a>19.强化学习中的policy如何设计？</h3><h3 id="20-人脸识别中的loss"><a href="#20-人脸识别中的loss" class="headerlink" title="20.人脸识别中的loss"></a>20.人脸识别中的loss</h3><p>直接使用softmax对应的cross-entropy存在的问题：</p>
<p>1.Softmax训练的深度特征，会把整个超空间或者超球，按照分类个数进行划分，保证类别是<strong>可分的</strong>。 这一点对多分类任务如MNIST和ImageNet非常合适，因为测试类别必定在训练类别中</p>
<p>2.但Softmax并<strong>不要求类内紧凑和类间分离</strong>，这一点非常不适合人脸识别任务，因为训练集的1W人数，    相对测试集整个世界70亿人类来说，非常微不足道，而我们不可能拿到所有人的训练样本，更过分的是，一般我们还要求训练集和测试集不重叠。</p>
<p>3.<strong>所以需要改造Softmax，除了保证可分性外，还要做到特征向量类内尽可能紧凑，类间尽可能分离</strong>。</p>
<p>改进的loss：</p>
<ul>
<li><p>Softmax + Contrastive Loss</p>
<p><img src="../images/contrast_loss.png" alt=""></p>
</li>
</ul>
<p>​        通过Contrastive loss来使同类特征的L2距离尽可能小，不同类特征的L2距离大于margin（间隔） m</p>
<ul>
<li><p>Triplet Loss</p>
<p>训练目标：</p>
<p><img src="../images/triplet_loss.png" alt=""></p>
</li>
</ul>
<p>​        找到若干三元组，一张作为anchor，positive与anchor为同一个人，negative为随机的不同人脸。训练目标是使anchor与positive的距离在学习之后变小，anchor与negative的距离在学习之后变大。</p>
<p>​        Triplet Loss:</p>
<p><img src="../images/triplet.png" alt=""></p>
<ul>
<li><p>Center Loss</p>
<p><img src="../images/center_loss.png" alt=""></p>
</li>
</ul>
<p>​        对每个类学习一个中心，并将每个类别的所有特征向量拉向对应类别中心。</p>
<p>​        学习效果：</p>
<p><img src="../images/center.png" alt=""></p>
<p>​        将原本不好分开的类别拉开。</p>
<p>​        各种改进的loss虽然很多，但主要思想都是<strong>增大类间距离，减小类内聚类。</strong></p>
<ul>
<li><p>focal loss(实际使用的，face.evolve中用的loss)</p>
<p>人脸识别存在的问题：<strong>负样本数量太大，占总的loss的大部分，而且多是容易分类的，因此使得模型的优化方向并不是我们所希望的那样</strong></p>
<p><strong>因此针对类别不均衡问题，作者提出一种新的损失函数：focal loss，这个损失函数是在标准交叉熵损失基础上修改得到的。这个函数可以通过减少易分类样本的权重，使得模型在训练时更专注于难分类的样本。</strong></p>
<p><img src="../images/focal_loss.png" alt=""></p>
</li>
</ul>
<p>​        其中，$α_t$为正负样本权重调制系数，当为正样本时，$α_t=a$，当为负样本时，$α_t=1-a$，因此通过调整a的值，可以调整正负样本在loss中占的权重。比如当正样本很多，可以取a为0-0.5之间的数，减少正样本对loss的贡献。</p>
<p>​        而$p_t$为预测值，如果$p_t$为0.9，表明这个样本为正样本的置信度很高，是容易分类样本；如果$p_t$为0.6，表明这个样本可能是正样本，但置信度不高，为难分类样本，通过在log前面加上$1-p_t$可以调整难分类样本对loss的贡献。</p>
<h3 id="21-yolo细节"><a href="#21-yolo细节" class="headerlink" title="21.yolo细节"></a>21.yolo细节</h3><p>画出结构？</p>
<h3 id="22-iou代码"><a href="#22-iou代码" class="headerlink" title="22.iou代码"></a>22.iou代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iou</span><span class="params">(p1,p2,p3,p4)</span>:</span></span><br><span class="line">	left_boundry = max(p1[<span class="number">0</span>], p3[<span class="number">0</span>])</span><br><span class="line">	right_boundry = min(p2[<span class="number">0</span>],p4[<span class="number">0</span>])</span><br><span class="line">	<span class="comment"># 这里定义y轴正方向竖直向下</span></span><br><span class="line">	top_boundry = max(p1[<span class="number">1</span>], p3[<span class="number">1</span>])</span><br><span class="line">	bottom_boundry = min(p2[<span class="number">1</span>], p4[<span class="number">1</span>])</span><br><span class="line">	s1 = abs(p1[<span class="number">0</span>]-p2[<span class="number">0</span>])*abs(p1[<span class="number">1</span>]-p2[<span class="number">1</span>])</span><br><span class="line">	s2 = abs(p3[<span class="number">0</span>]-p4[<span class="number">0</span>])*abs(p3[<span class="number">1</span>]-p4[<span class="number">1</span>])</span><br><span class="line">	union = (bottom_boundry-top_boundry)*(right_boundry-left_boundry)</span><br><span class="line">	<span class="keyword">return</span> max(union/(s1+s2-union), <span class="number">0</span>)</span><br></pre></td></tr></table></figure>



<h3 id="23-深度可分离卷积"><a href="#23-深度可分离卷积" class="headerlink" title="23.深度可分离卷积"></a>23.深度可分离卷积</h3><p>怎么做？是否会带来性能损失？</p>
<p><img src="../images/seperable_conv.png" alt=""></p>
<p>根据inception net改进的结构， 将基本inception module替换为使用Depthwise Conv + Pointwise Conv ，进一步提升了计算效率。</p>
<ul>
<li>1x1卷积，Pointwise Conv，用来学习不同channel之间的关联关系</li>
<li>3x3卷积，spatial convolution，即Depthwise Conv，用来学习单个channel内部空间的关联关系</li>
</ul>
<p>这个结构由google提出，轻量级网络MobileNets即是基于这种结构。</p>
<h3 id="24-DQN如何体现最大化reward"><a href="#24-DQN如何体现最大化reward" class="headerlink" title="24.DQN如何体现最大化reward?"></a>24.DQN如何体现最大化reward?</h3><p>首先明确，DQN是一种迭代算法，通过不断得迭代来求解最优policy。</p>
<p>先回顾使用Q表的Q-learning。</p>
<p><img src="../images/Q-learning.png" alt=""></p>
<ol>
<li><p>首先在状态s1采取行为a2到达状态s2，这时需要更新Q表的值，即更新一个新的Q(s1, a2)。</p>
</li>
<li><p>Q(s1,a2)现实是由实际奖励，加上一个衰减因子γ乘以Q（s2）所能获得的最大奖励，在这里为在s2下选取a2时候的奖励2。</p>
</li>
<li><p>利用现实-估计得到差值，按照更新公式来得到新的Q（s1,a2）。</p>
</li>
<li><p>此时还没有在s2的时候做出行为。</p>
</li>
</ol>
<p>Q-learning整体算法：</p>
<p><img src="../images/Q-learning%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B.png" alt=""></p>
<p>可以看出，Q-learning是一种不断做出行为，不断修改Q表的算法。（迭代）</p>
<p>说回DQN：</p>
<p><img src="../images/DQN%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B.png" alt=""></p>
<p>​        DQN是为了解决Q表过大的问题，用神经网络来代替Q表。用Q-learning的思路来说，就是通过最小化$Q_{现实}-Q_{估计}$来迭代出最优的policy。和policy gradient这种通过最大化奖励的方式来得到最优policy的方式有所区别。</p>
<h3 id="25-Transformer结构"><a href="#25-Transformer结构" class="headerlink" title="25.Transformer结构"></a>25.Transformer结构</h3><p>可参考知乎文章“<a href="https://zhuanlan.zhihu.com/p/48508221" target="_blank" rel="noopener">《详解Transformer （Attention Is All You Need）》</a>“</p>
<p>​        Transformer中抛弃了传统的CNN和RNN，整个网络结构完全是由Attention机制组成。更准确地讲, Transformer由且仅由self-Attenion和Feed Forward Neural Network组成。一个基于Transformer的可训练的神经网络可以通过堆叠Transformer的形式进行搭建，作者的实验是通过搭建编码器和解码器各6层，总共12层的Encoder-Decoder，并在机器翻译中取得了BLEU值得新高。</p>
<p>​        看了淘宝和美团将transformer结构用于推荐系统的文章，发现都只采用了encoder部分，利用了transformer结构中内置的attention部分，来做特征的高阶组合、学习特征之间的交叉关系等。可以用在特征工程，行为序列建模，重排序，预测用户u点击item vt的概率等。</p>
<p>transformer结构：</p>
<p>1.整体结构</p>
<p><img src="../images/transformer1.jpg" alt=""></p>
<p>2.encoder-decoder结构</p>
<p><img src="../images/encoder-decoder%E7%BB%93%E6%9E%84.png" alt=""></p>
<p><img src="../images/encoder-decoder%E7%BB%93%E6%9E%842.jpg" alt=""></p>
<p><img src="../images/encoder.jpg" alt=""></p>
<p>可以看到，encode结构包括了一个self-attention和FFN。</p>
<p>其中：</p>
<p><img src="../images/self-attention.png" alt=""></p>
<p>有关Q，K，V见下方</p>
<p><img src="../images/FFN.png" alt=""></p>
<p>decoder结构：</p>
<p><img src="../images/decoder.jpg" alt=""></p>
<p>输入：</p>
<p><img src="../images/%E8%BE%93%E5%85%A5.jpg" alt=""></p>
<p>self-attention：</p>
<p><img src="../images/self-attention1.jpg" alt=""></p>
<ol>
<li>如上文，将输入单词转化成嵌入向量；</li>
<li>根据嵌入向量得到 <img src="https://www.zhihu.com/equation?tex=q" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=v" alt="[公式]"> 三个向量；</li>
<li>为每个向量计算一个score： <img src="https://www.zhihu.com/equation?tex=%5Ctext%7Bscore%7D+%3D+q+%5Ccdot+k" alt="[公式]"> ；</li>
<li>为了梯度的稳定，Transformer使用了score归一化，即除以 <img src="https://www.zhihu.com/equation?tex=%5Csqrt%7Bd_k%7D" alt="[公式]"> ；</li>
<li>对score施以softmax激活函数；</li>
<li>softmax点乘Value值 <img src="https://www.zhihu.com/equation?tex=v" alt="[公式]"> ，得到加权的每个输入向量的评分 <img src="https://www.zhihu.com/equation?tex=v" alt="[公式]"> ；</li>
<li>相加之后得到最终的输出结果 <img src="https://www.zhihu.com/equation?tex=z" alt="[公式]"> ： <img src="https://www.zhihu.com/equation?tex=z%3D%5Csum+v" alt="[公式]"> 。</li>
</ol>
<p><img src="../images/self-attention2.jpg" alt=""></p>
<p>矩阵：</p>
<p><img src="../images/self-attention%E7%9F%A9%E9%98%B5.jpg" alt=""></p>
<p>attention公式矩阵形式：</p>
<p><img src="../images/self-attention%E7%9F%A9%E9%98%B51.jpg" alt=""></p>
<p>encoder内部的残差结构：</p>
<p><img src="../images/encoder%E6%AE%8B%E5%B7%AE.jpg" alt=""></p>
<p>采用multi-head attention的形式：</p>
<p>Multi-Head Attention相当于 <img src="https://www.zhihu.com/equation?tex=h" alt="[公式]"> 个不同的self-attention的集成（ensemble），在这里我们以 <img src="https://www.zhihu.com/equation?tex=h%3D8" alt="[公式]"> 举例说明。Multi-Head Attention的输出分成3步：</p>
<ol>
<li>将数据 <img src="https://www.zhihu.com/equation?tex=X+" alt="[公式]"> 分别输入到图13所示的8个self-attention中，得到8个加权后的特征矩阵 <img src="https://www.zhihu.com/equation?tex=Z_i%2C+i%5Cin%5C%7B1%2C2%2C...%2C8%5C%7D" alt="[公式]"> 。</li>
<li>将8个 <img src="https://www.zhihu.com/equation?tex=Z_i" alt="[公式]"> 按列拼成一个大的特征矩阵；</li>
<li>特征矩阵经过一层全连接后得到输出 <img src="https://www.zhihu.com/equation?tex=Z" alt="[公式]"> 。</li>
</ol>
<p><img src="../images/multi-head.jpg" alt=""></p>
<p>完整结构：</p>
<p><img src="../images/transformer%E5%AE%8C%E6%95%B4%E7%BB%93%E6%9E%84.jpg" alt=""></p>
<p>在谷歌论文中，由于transformer结构没有捕捉顺序结构的能力，因此还引入了位置编码：</p>
<p><img src="../images/%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81.jpg" alt=""></p>
<p>参考文献：</p>
<ol>
<li>吴恩达 deeplearning 课程</li>
<li>@zhwhong,  “<a href="https://www.jianshu.com/p/c61ae11cc5f6" target="_blank" rel="noopener">机器学习之分类性能度量指标 : ROC曲线、AUC值、正确率、召回率</a>“</li>
<li>@刘建平Pinard,  “<a href="https://www.cnblogs.com/pinard/p/9426283.html" target="_blank" rel="noopener">强化学习（二）马尔科夫决策过程(MDP)</a>”</li>
<li>@YaqiLYU,   “<a href="https://zhuanlan.zhihu.com/p/34404607" target="_blank" rel="noopener">人脸识别的LOSS（上）</a>“</li>
<li>@莫烦python,  “<a href="https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/2-1-A-q-learning/" target="_blank" rel="noopener">什么是Q-learning</a>“</li>
<li></li>
</ol>

      <blockquote class="mdui-m-t-5">
        
        <strong>本文链接：</strong><a href="http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/">http://clownw.github.io/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/</a>
      </blockquote>
      
    </div>
    <footer class="mdui-card-actions">
      
      
        <a class="mdui-ripple article_tags-link" href="../tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">神经网络</a>
      
    </footer>
    
  </article>
  
<script src="../https:/cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="../https:/cdn.bootcss.com/fancybox/3.5.7/jquery.fancybox.min.js"></script>

  <script>$("#main article .mdui-card-content img.fancybox").on("click",function(e){$.fancybox.open({src:$(this).attr("src")});});</script>


  <nav id="paginator">
    
      <a rel="prev" class="extend prev" href="../%E5%9B%9E%E6%BA%AF%E6%B3%95/">
        <button aria-label="prev" class="mdui-btn mdui-btn-raised mdui-btn-dense mdui-btn-icon mdui-color-theme-accent mdui-ripple"><i class="mdui-icon material-icons">arrow_back</i></button>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上一篇
      </a>
    
    <div class="spacer"></div>
    
      <a rel="next" class="extend next" href="../%E5%A0%86%E6%A0%88/">
        下一篇&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <button aria-label="next" class="mdui-btn mdui-btn-raised mdui-btn-dense mdui-btn-icon mdui-color-theme-accent mdui-ripple"><i class="mdui-icon material-icons">arrow_forward</i></button>
      </a>
    
  </nav>



</main>
  <footer id="footer" class="mdui-m-t-5 mdui-p-y-3 mdui-color-theme">
  <div class="mdui-p-y-0 mdui-text-center">
    
    
    
    
    
    
    
    
    
    
    
    
  </div>
  <div class="mdui-p-y-1 mdui-text-center">
    Copyright &copy; 2019 - 2020 ClownW<br>
    Powered by <a href="https://hexo.io/" target="_blank" class="mdui-text-color-theme-accent">Hexo</a>
    
  </div>
</footer>
  <button id="gotop" class="mdui-fab mdui-fab-fixed mdui-fab-hide mdui-ripple mdui-color-theme-accent"><i class="mdui-icon material-icons">arrow_upward</i></button>
  
  
<script src="../js/mdui.js"></script>
<script src="../js/script.js"></script>

</body>
</html>